{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "bigram_LM.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cNZKJddsssP",
        "colab_type": "text"
      },
      "source": [
        "Важное:\n",
        "1. Один скрипт должен считать входной корпус из файла (ов), обработать его и в каком-то формате записать «модель» в другой файл\n",
        "2. Другой скрипт должен принимать на вход путь до этой модели и опционально префикс генерируемого текста и генерировать его правдоподобное продолжение.\n",
        "3. Основной код должен быть разбит на две части: обучение и генерация.\n",
        "4. Удобно создать для обучения и генерации отдельные файлы и реализовать консольный интерфейс к ним через argparse\n",
        "\n",
        "Дополнительное:\n",
        "1. Считать входные данные из файлов.\n",
        "2. Очистить тексты: выкидывать неалфавитные символы, приводить к lowercase.\n",
        "3. Разбить тексты на слова (в ML это называется токенизацией).\n",
        "4. Сохранить модель в каком-нибудь формате, который позволяет восстановить слова и частоты биграмм.\n",
        "5. Загрузить модель.\n",
        "6. Инициализировать её каким-нибудь сидом.\n",
        "7. Сгенерировать последовательность нужной длины.\n",
        "8. Следуйте принципам ООП. Оберните модель в класс, у которого будет методы fit и generate.\n",
        "9. Для сохранения модели удобно использовать pickle или dill.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "unXRxzIl3gYi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 722
        },
        "outputId": "fe69f119-de3b-418e-d7a7-91775a7c1d22"
      },
      "source": [
        "import math \n",
        "import numpy as np\n",
        "\n",
        "TrainLines = []\n",
        "Words = []\n",
        "AssessmentTest = []\n",
        "SentLength = []\n",
        "ConfusionCoef = []\n",
        "\n",
        "Dictionary = {'<s>': 0, '</s>': 0, '<NN>': 1}\n",
        "BiDictionary = {'<NN> <NN>':0}\n",
        "BiProbs = {}\n",
        "\n",
        "for line in open('/content/text.txt'):\n",
        "    if line.strip():\n",
        "        TrainLines.append(line.strip())\n",
        "TrainLines = [line.strip() for line in open('/content/test.txt')]\n",
        "\n",
        "for line in TrainLines:\n",
        "    Dictionary['<s>'] += 1\n",
        "    Words.append('<s>') \n",
        "    Dictionary['</s>'] += 1\n",
        "\n",
        "    for word in line.split():       \n",
        "        Words.append(word)\n",
        "        \n",
        "        if word not in Dictionary: Dictionary[word] = 1\n",
        "        else: Dictionary[word] += 1\n",
        "    Words.append('</s>')\n",
        "  \n",
        "Vocabulary = set(Dictionary)\n",
        "listVocab = list(Vocabulary)\n",
        "\n",
        "CountTokens = sum(Dictionary.values())\n",
        "print('------------------------------------')\n",
        "print('Words for train', len(Words))\n",
        "print('Vocabulary size:', len(Vocabulary))\n",
        "print('Vocabulary examples:', listVocab[0:2])\n",
        "print('------------------------------------')\n",
        "\n",
        "for Word1, Word2 in zip(Words, Words[1:]): \n",
        "    OneBi = Word1 + ' ' + Word2\n",
        "    if OneBi not in BiDictionary: BiDictionary[OneBi] = 1\n",
        "    else: BiDictionary[OneBi] += 1\n",
        "\n",
        "for Key in BiDictionary: BiDictionary[Key] += 1\n",
        "print('Size BiDictionary:', len(BiDictionary))\n",
        "\n",
        "for Key in BiDictionary:\n",
        "    Word1, Word2 = Key.split()\n",
        "    probability = BiDictionary[Key] / (Dictionary[Word1] + len(Vocabulary))\n",
        "    BiProbs[Key] = probability\n",
        "        \n",
        "print('Size BiProbs:', len(BiProbs))\n",
        "vocabularySize = len(Dictionary)\n",
        "\n",
        "print('------------------------------------')\n",
        "for line in TrainLines:\n",
        "    print('Line',TrainLines.index(line) + 1,': ', line, '\\n')\n",
        "    words = line.split()\n",
        "    words.insert(0, '<s>')\n",
        "    words.append('</s>')\n",
        "    \n",
        "    SentLength.append(len(words))\n",
        "    \n",
        "    BiTest = []\n",
        "    for Word1, Word2 in zip(words,words[1:]): \n",
        "        OneBi = Word1 + ' ' + Word2\n",
        "        BiTest.append(OneBi)\n",
        "    print('Bigrams:\\n', BiTest, '\\n')\n",
        "    \n",
        "    Product = 1\n",
        "    \n",
        "    for i in range(len(BiTest)):\n",
        "        firstWordProbability = 1\n",
        "        CurrentBi = BiTest[i]\n",
        "                  \n",
        "        if CurrentBi not in BiProbs: CurrentBi = '<NN> <NN>'\n",
        "        Product = Product * BiProbs[CurrentBi] \n",
        "        \n",
        "    print('Product:', Product, '\\n')\n",
        "    AssessmentTest.append(Product)\n",
        "\n",
        "print('------------------------------------')\n",
        "print('Probabilties for test:', AssessmentTest)\n",
        "print('Sentence lengths:', SentLength)\n",
        "\n",
        "normalizedBySentenceLength = []\n",
        "\n",
        "for i in range(len(AssessmentTest)):\n",
        "    normalizedProb1 = math.exp(math.log(AssessmentTest[i]) / SentLength[i])\n",
        "    normalizedBySentenceLength.append(normalizedProb1)\n",
        "    \n",
        "#print('P normalized by sentence length:', normalizedBySentenceLength)\n",
        "\n",
        "for i in range(len(AssessmentTest)):\n",
        "    perplexity = (1 / AssessmentTest[i]) ** (1/SentLength[i])\n",
        "    ConfusionCoef.append(perplexity)\n",
        "  \n",
        "print('------------------------------------')\n",
        "print('Confusion Coefficient:', ConfusionCoef)\n",
        "OUTPUT = open('output.txt','w') \n",
        "\n",
        "for i in range(len(AssessmentTest)): OUTPUT.write(str(AssessmentTest[i]) + ',' + str(normalizedBySentenceLength[i]) + ',' + str(ConfusionCoef[i]) + '\\n')\n",
        "OUTPUT.close() \n",
        "\n",
        "YourSentence = '<s>'\n",
        "CurrentWord = '<s>'\n",
        "while CurrentWord != '</s>' and CurrentWord != '.' and CurrentWord != '?': \n",
        "    PossibleNextWord = []\n",
        "    for Key in BiDictionary:\n",
        "        Word1, Word2 = Key.split()\n",
        "        if Word1 == CurrentWord:\n",
        "            PossibleNextWord.append(Word2)\n",
        "\n",
        "    OneArray = np.array(PossibleNextWord) \n",
        "    NextWord = np.random.choice(a = OneArray) \n",
        "    YourSentence = YourSentence + ' ' + NextWord\n",
        "    CurrentWord = NextWord"
      ],
      "execution_count": 401,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "------------------------------------\n",
            "Words for train 12\n",
            "Vocabulary size: 7\n",
            "Vocabulary examples: ['<s>', 'должен']\n",
            "------------------------------------\n",
            "Size BiDictionary: 10\n",
            "Size BiProbs: 10\n",
            "------------------------------------\n",
            "Line 1 :  Здесь \n",
            "\n",
            "Bigrams:\n",
            " ['<s> Здесь', 'Здесь </s>'] \n",
            "\n",
            "Product: 0.045454545454545456 \n",
            "\n",
            "Line 2 :  должен \n",
            "\n",
            "Bigrams:\n",
            " ['<s> должен', 'должен </s>'] \n",
            "\n",
            "Product: 0.045454545454545456 \n",
            "\n",
            "Line 3 :  быть \n",
            "\n",
            "Bigrams:\n",
            " ['<s> быть', 'быть </s>'] \n",
            "\n",
            "Product: 0.045454545454545456 \n",
            "\n",
            "Line 4 :  текст \n",
            "\n",
            "Bigrams:\n",
            " ['<s> текст', 'текст </s>'] \n",
            "\n",
            "Product: 0.045454545454545456 \n",
            "\n",
            "------------------------------------\n",
            "Probabilties for test: [0.045454545454545456, 0.045454545454545456, 0.045454545454545456, 0.045454545454545456]\n",
            "Sentence lengths: [3, 3, 3, 3]\n",
            "------------------------------------\n",
            "Confusion Coefficient: [2.802039330655387, 2.802039330655387, 2.802039330655387, 2.802039330655387]\n",
            "<s> быть </s>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F265EX_0EUyP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "51ceebb5-b0db-46af-e385-a6a557113d69"
      },
      "source": [
        "print(YourSentence)"
      ],
      "execution_count": 402,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<s> быть </s>\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}